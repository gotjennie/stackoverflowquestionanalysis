(dp0
Vhas_more
p1
I00
sVitems
p2
(lp3
(dp4
Vbody
p5
V<p>Construct a Series first, then resetting the index will give you a DataFrame:</p>\u000a\u000a<pre><code>pd.Series(d).reset_index()\u000aOut: \u000a  level_0 level_1  0\u000a0   first     row  3\u000a1  second     row  1\u000a</code></pre>\u000a\u000a<p>You can rename columns afterwards:</p>\u000a\u000a<pre><code>df = pd.Series(d).reset_index()   \u000adf.columns = ['Col1', 'Col2', 'Col3']   \u000adf\u000aOut: \u000a     Col1 Col2  Col3\u000a0   first  row     3\u000a1  second  row     1\u000a</code></pre>\u000a
p6
sVquestion_id
p7
I44012099
sVlast_activity_date
p8
I1494971248
sVcreation_date
p9
I1494971248
sVscore
p10
I9
sVowner
p11
(dp12
Vuser_id
p13
I2285236
sVprofile_image
p14
Vhttps://www.gravatar.com/avatar/5ac8c2e0f71dbd8cf4543039bebf2ab3?s=128&d=identicon&r=PG&f=1
p15
sVuser_type
p16
Vregistered
p17
sVreputation
p18
I19710
sVlink
p19
Vhttp://stackoverflow.com/users/2285236/ayhan
p20
sVaccept_rate
p21
I90
sVdisplay_name
p22
Vayhan
p23
ssVis_accepted
p24
I01
sVanswer_id
p25
I44012152
sa(dp26
Vbody
p27
V<p>On reclamation of a generator object, Python calls its <code>close</code> method, raising a <code>GeneratorExit</code> exception at the point of its last <code>yield</code> if it wasn't already finished executing. As this <code>GeneratorExit</code> propagates, it triggers the <code>__exit__</code> method of the context manager you used.</p>\u000a\u000a<p>This was introduced in Python 2.5, <a href="https://www.python.org/dev/peps/pep-0342/" rel="nofollow noreferrer">in the same PEP as <code>send</code> and yield expressions</a>. Before then, you couldn't <code>yield</code> inside a <code>try</code> with a <code>finally</code>, and if <code>with</code> statements had existed pre-2.5, you wouldn't have been able to <code>yield</code> inside one either.</p>\u000a
p28
sVquestion_id
p29
I44005817
sVlast_activity_date
p30
I1494954647
sVcreation_date
p31
I1494954647
sVscore
p32
I3
sVowner
p33
(dp34
Vuser_id
p35
I2357112
sVprofile_image
p36
Vhttps://www.gravatar.com/avatar/3f80897d57525afe9eac4fb8c8318052?s=128&d=identicon&r=PG
p37
sVuser_type
p38
Vregistered
p39
sVreputation
p40
I94866
sVlink
p41
Vhttp://stackoverflow.com/users/2357112/user2357112
p42
sVaccept_rate
p43
I33
sVdisplay_name
p44
Vuser2357112
p45
ssVis_accepted
p46
I01
sVanswer_id
p47
I44007670
sa(dp48
Vbody
p49
V<p>In CPython, go ahead.  Under the covers, the only real difference between the storage of lists and tuples is that the C-level array holding the tuple elements is allocated <em>in</em> the tuple object, while a list object contains a pointer <em>to</em> a C-level array holding the list elements, which is allocated separately from the list object.  The list implementation needs to do that because the list may grow, and so the memory containing the C-level vector may need to change its base address.  A tuple can't change size, so the memory for it is allocated directly in the tuple object.</p>\u000a\u000a<p>I've created tuples with millions of elements, and yet I lived to type about it ;-)</p>\u000a\u000a<h2>Obscure</h2>\u000a\u000a<p>In CPython, there can even be "a reason" to prefer giant tuples:  the cyclic garbage collection scheme exempts a tuple from periodic scanning if it only contains immutable objects.  Then the tuple can never be part of a cycle, so cyclic gc can ignore it.  The same optimization cannot be used for lists; just because a list contains only immutable objects during one run of cyclic gc says nothing about whether that will still be the case during the next run.</p>\u000a\u000a<p>This is almost never highly significant, but it can save a percent or so in a long-running program, and the benefit of exempting giant tuples grows the bigger they are.</p>\u000a
p50
sVquestion_id
p51
I43988667
sVlast_activity_date
p52
I1494883900
sVcreation_date
p53
I1494882383
sVscore
p54
I9
sVowner
p55
(dp56
Vuser_id
p57
I2705542
sVprofile_image
p58
Vhttps://www.gravatar.com/avatar/ffc22708f70324dcbfe34f247637ca01?s=128&d=identicon&r=PG&f=1
p59
sVuser_type
p60
Vregistered
p61
sVreputation
p62
I29728
sVlink
p63
Vhttp://stackoverflow.com/users/2705542/tim-peters
p64
sVdisplay_name
p65
VTim Peters
p66
ssVis_accepted
p67
I01
sVlast_edit_date
p68
I1494883900
sVanswer_id
p69
I43988809
sa(dp70
Vbody
p71
V<p>You can use <a href="http://www.regular-expressions.info/lookaround.html" rel="noreferrer">look-ahead assertion</a> which does not consume matched string:</p>\u000a\u000a<pre><code>&gt;&gt;&gt; re.findall(r'(?=([a-z]{2,})(?=.*\u005c1))', 'aabaacaba')\u000a['aa', 'aba', 'ba']\u000a</code></pre>\u000a\u000a<p>NOTE: <code>aba</code> matched instead of <code>ab</code>. (trying to match as long as possible)</p>\u000a
p72
sVquestion_id
p73
I43959719
sVlast_activity_date
p74
I1494730460
sVcreation_date
p75
I1494730460
sVscore
p76
I8
sVowner
p77
(dp78
Vuser_id
p79
I2225682
sVprofile_image
p80
Vhttps://www.gravatar.com/avatar/4958f4712d94ab82fe55fa471308e4b5?s=128&d=identicon&r=PG
p81
sVuser_type
p82
Vregistered
p83
sVreputation
p84
I195339
sVlink
p85
Vhttp://stackoverflow.com/users/2225682/falsetru
p86
sVdisplay_name
p87
Vfalsetru
p88
ssVis_accepted
p89
I01
sVanswer_id
p90
I43959935
sa(dp91
Vbody
p92
V<p>You can use decorators (if you don't know them you can refer to <a href="https://www.python.org/dev/peps/pep-0318" rel="noreferrer">PEP-318</a>):</p>\u000a\u000a<pre><code>def decorator(method):\u000a    def decorated_method(self, *args, **kwargs):\u000a        # before the method call\u000a        if self.busy:\u000a            return None\u000a        self.busy = True\u000a\u000a        # the actual method call\u000a        result = method(self, *args, **kwargs)  \u000a\u000a        # after the method call\u000a        self.busy = False\u000a\u000a        return result\u000a\u000a    return decorated_method\u000a\u000aclass Thing():\u000a    def __init__(self):\u000a        self.busy = False\u000a\u000a    @decorator\u000a    def func_1(self):\u000a        ...\u000a\u000a    @decorator\u000a    def func_2(self):\u000a        ...\u000a</code></pre>\u000a\u000a<p>You might want to use <a href="https://docs.python.org/library/functools.html#functools.wraps" rel="noreferrer"><code>functools.wraps</code></a> if you want the decorated method to "look like" the original method. The <code>@decorator</code> is just syntactic sugar, you could also apply the decorator explicitly:</p>\u000a\u000a<pre><code>class Thing():\u000a    def __init__(self):\u000a        self.busy = False\u000a\u000a    def func_1(self):\u000a        ...\u000a\u000a    func_1 = decorator(func_1)  # replace "func_1" with the decorated "func_1"\u000a</code></pre>\u000a\u000a<p>In case you really want to apply it to all methods you can additionally use a class decorator:</p>\u000a\u000a<pre><code>def decorate_all_methods(cls):\u000a    for name, method in cls.__dict__.items():\u000a        if name.startswith('_'):  # don't decorate private functions\u000a            continue \u000a        setattr(cls, name, decorator(method))\u000a    return cls\u000a\u000a@decorate_all_methods\u000aclass Thing():\u000a    def __init__(self):\u000a        self.busy = False\u000a\u000a    def func_1(self):\u000a        ...\u000a\u000a    def func_2(self):\u000a        ...\u000a</code></pre>\u000a
p93
sVquestion_id
p94
I43948359
sVlast_activity_date
p95
I1494641237
sVcreation_date
p96
I1494639031
sVscore
p97
I10
sVowner
p98
(dp99
Vuser_id
p100
I5393381
sVprofile_image
p101
Vhttps://www.gravatar.com/avatar/308ffa6266fda6d94bc56fbd9e9798f9?s=128&d=identicon&r=PG&f=1
p102
sVuser_type
p103
Vregistered
p104
sVreputation
p105
I28421
sVlink
p106
Vhttp://stackoverflow.com/users/5393381/mseifert
p107
sVaccept_rate
p108
I94
sVdisplay_name
p109
VMSeifert
p110
ssVis_accepted
p111
I01
sVlast_edit_date
p112
I1494641237
sVanswer_id
p113
I43948381
sa(dp114
Vbody
p115
V<p>A simple way is:</p>\u000a\u000a<pre><code>def test():\u000a    for number in range(0,10):\u000a        yield number \u000a        yield number**2\u000a</code></pre>\u000a
p116
sVquestion_id
p117
I43903437
sVlast_activity_date
p118
I1494598224
sVcreation_date
p119
I1494454713
sVscore
p120
I11
sVowner
p121
(dp122
Vuser_id
p123
I6184799
sVprofile_image
p124
Vhttps://www.gravatar.com/avatar/0c8443804746f889fa902daf6966f54a?s=128&d=identicon&r=PG&f=1
p125
sVuser_type
p126
Vregistered
p127
sVreputation
p128
I136
sVlink
p129
Vhttp://stackoverflow.com/users/6184799/carlos-rodrigues
p130
sVdisplay_name
p131
Vcarlos rodrigues
p132
ssVis_accepted
p133
I01
sVlast_edit_date
p134
I1494598224
sVanswer_id
p135
I43903580
sa(dp136
Vbody
p137
V<p>This solution is more explicit and less pandas-esque, but it involves only a single pass through all rows without creating tons of temporary columns, and is therefore possibly faster. It needs an additional state variable, which I wrapped it into a closure for not having to make a class. </p>\u000a\u000a<pre><code>def closure():\u000a    cur_weight = {}\u000a    def func(x):\u000a        if x["Percentile"] &gt; 0.7:\u000a            next_weight = x["Weight"]\u000a        elif x["Percentile"] &lt; 0.5 :\u000a            next_weight = 0\u000a        else:\u000a            next_weight = x["Weight"] if cur_weight.get(x["Stock"], 0) &gt; 0 else 0\u000a        cur_weight[x["Stock"]] = next_weight\u000a        return next_weight\u000a    return func\u000a\u000adf["FinalWeight"] = df.apply(closure(), axis=1)\u000a</code></pre>\u000a
p138
sVquestion_id
p139
I43791970
sVlast_activity_date
p140
I1494576336
sVcreation_date
p141
I1494576336
sVscore
p142
I4
sVowner
p143
(dp144
Vuser_id
p145
I1798300
sVprofile_image
p146
Vhttps://www.gravatar.com/avatar/5d3af7cd3d04060a697f4926f0f8578c?s=128&d=identicon&r=PG
p147
sVuser_type
p148
Vregistered
p149
sVreputation
p150
I1278
sVlink
p151
Vhttp://stackoverflow.com/users/1798300/cronos
p152
sVdisplay_name
p153
Vcronos
p154
ssVis_accepted
p155
I01
sVanswer_id
p156
I43932573
sa(dp157
Vbody
p158
V<p>There are several pitfalls to having a <code>defaultdict</code> be the Enum's namespace:</p>\u000a\u000a<ul>\u000a<li>unable to access anything but other enum members/methods</li>\u000a<li>typos create new members</li>\u000a<li>lose protections form <code>_EnumDict</code> namespace:\u000a\u000a<ul>\u000a<li>overwriting members</li>\u000a<li>overwriting methods</li>\u000a<li>the newer <code>_generate</code> method</li>\u000a</ul></li>\u000a</ul>\u000a\u000a<p>And the most important:</p>\u000a\u000a<ul>\u000a<li>it will not work</li>\u000a</ul>\u000a\u000a<p>Why won't it work?  Not only can <code>__prepare__</code> set attributes on the namespace dict, so can the namespace dict itself -- and <code>_EnumDict</code> does: <code>_member_names</code>, a list of all the attributes that should be members.</p>\u000a\u000a<p>However, the goal of declaring a name without a value is not impossible -- the <a href="https://pypi.python.org/pypi/aenum" rel="nofollow noreferrer"><code>aenum</code></a><sup>1</sup> package allows it with a few safeguards:</p>\u000a\u000a<ul>\u000a<li>magic auto behavior is only present while defining members (as soon as a normal method is defined it turns off)</li>\u000a<li><code>property</code>, <code>classmethod</code>, and <code>staticmethod</code> are excluded by default, but one can include them and/or exclude other global names</li>\u000a</ul>\u000a\u000a<p>This behavior was deemed too magical for the stdlib, though, so if you want it, along with some other enhancements/improvements<sup>2</sup>, you'll have to use <code>aenum</code>.</p>\u000a\u000a<p>An example:</p>\u000a\u000a<pre><code>from aenum import AutoEnum\u000a\u000aclass Color(AutoEnum):\u000a    red\u000a    green\u000a    blue\u000a</code></pre>\u000a\u000a<p>The <code>__repr__</code> still shows the created values, though.</p>\u000a\u000a<p>--</p>\u000a\u000a<p><sup>1</sup> Disclosure:  I am the author of the <a href="https://docs.python.org/3/library/enum.html" rel="nofollow noreferrer">Python stdlib <code>Enum</code></a>, the <a href="https://pypi.python.org/pypi/enum34" rel="nofollow noreferrer"><code>enum34</code> backport</a>, and the <a href="https://pypi.python.org/pypi/aenum" rel="nofollow noreferrer">Advanced Enumeration (<code>aenum</code>)</a>  library.</p>\u000a\u000a<p><sup>2</sup> <code>NamedConstant</code> (just like it says ;), <code>NamedTuple</code> (metaclass based, default values, etc.), plus some built-in Enums:</p>\u000a\u000a<ul>\u000a<li><code>MultiValueEnum</code>  --> several values can map to one name (not aliases)</li>\u000a<li><code>NoAliasEnum</code> --> names with the same value are not aliases (think playing cards)</li>\u000a<li><code>OrderedEnum</code> --> members are order-comparable by definition</li>\u000a<li><code>UniqueEnum</code> --> no aliases allowed</li>\u000a</ul>\u000a
p159
sVquestion_id
p160
I43855102
sVlast_activity_date
p161
I1494509992
sVcreation_date
p162
I1494270729
sVscore
p163
I7
sVowner
p164
(dp165
Vuser_id
p166
I208880
sVprofile_image
p167
Vhttps://www.gravatar.com/avatar/de311342220232e618cb27c9936ab9bf?s=128&d=identicon&r=PG
p168
sVuser_type
p169
Vregistered
p170
sVreputation
p171
I27034
sVlink
p172
Vhttp://stackoverflow.com/users/208880/ethan-furman
p173
sVaccept_rate
p174
I76
sVdisplay_name
p175
VEthan Furman
p176
ssVis_accepted
p177
I01
sVlast_edit_date
p178
I1494509992
sVanswer_id
p179
I43855536
sa(dp180
Vbody
p181
V<p>How does this work for you?</p>\u000a\u000a<pre><code>import os\u000aimport pathlib\u000a\u000aOLD_DIR = 'files'\u000aNEW_DIR = 'new_dir'\u000a\u000ap = pathlib.Path(OLD_DIR)\u000afor f in p.glob('**/*.xml'):\u000a    new_name = '{}_{}'.format(f.parent.name, f.name)\u000a    f.rename(os.path.join(NEW_DIR, new_name))\u000a</code></pre>\u000a\u000a<p>If you don't have a modern version of Python (3.5+) you can also just use glob, os, and shutil:</p>\u000a\u000a<pre><code>import os\u000aimport glob\u000aimport shutil\u000a\u000a\u000afor f in glob.glob('files/**/*.xml'):\u000a    new_name = '{}_{}'.format(os.path.basename(os.path.dirname(f)), os.path.basename(f))\u000a    shutil.move(f, os.path.join('new_dir', new_name))\u000a</code></pre>\u000a
p182
sVquestion_id
p183
I43854049
sVlast_activity_date
p184
I1494450388
sVcreation_date
p185
I1494449969
sVscore
p186
I8
sVowner
p187
(dp188
Vuser_id
p189
I344286
sVprofile_image
p190
Vhttps://www.gravatar.com/avatar/3827b2facd01ed6a64a96df00d4b877a?s=128&d=identicon&r=PG
p191
sVuser_type
p192
Vregistered
p193
sVreputation
p194
I21896
sVlink
p195
Vhttp://stackoverflow.com/users/344286/wayne-werner
p196
sVaccept_rate
p197
I93
sVdisplay_name
p198
VWayne Werner
p199
ssVis_accepted
p200
I01
sVlast_edit_date
p201
I1494450388
sVanswer_id
p202
I43902649
sa(dp203
Vbody
p204
V<p>There's a somewhat pragmatic reason <code>__del__</code> is still around. Several signficant <code>weakref</code> improvements, including <code>finalize</code>, were <a href="https://docs.python.org/3.4/whatsnew/3.4.html#weakref" rel="nofollow noreferrer">new in Python 3.4</a>. So, replacing <code>__del__</code> with better weakrefs missed the window for language breaking changes with py3k.</p>\u000a\u000a<p>I think most uses <em>can</em> be replaced by the base weakref functionality, but I'm struck by this observation from Richard Oudkerk in <a href="https://bugs.python.org/issue15528" rel="nofollow noreferrer">issue 15528</a> where proposed and implemented <code>finalize</code>:</p>\u000a\u000a<blockquote>\u000a  <p>[Weakref callbacks] are low level, and working out how to use them correctly requires a bit of head scratching.  One must find somewhere to store the weakref till after the referent is dead, and without accidentally keeping the referent alive.  Then one must ensure that the callback frees the weakref (without leaving any remnant ref-cycles).</p>\u000a  \u000a  <p>When it is an option, using a <code>__del__</code> method is far less hassle.</p>\u000a</blockquote>\u000a\u000a<p>Anyway, perhaps the question should be brought up again when Python 4 is being considered? ;)</p>\u000a
p205
sVquestion_id
p206
I43758886
sVlast_activity_date
p207
I1494372762
sVcreation_date
p208
I1494372762
sVscore
p209
I2
sVowner
p210
(dp211
Vuser_id
p212
I3665
sVprofile_image
p213
Vhttps://www.gravatar.com/avatar/8cf559941da0220c8423ddb50efe42ec?s=128&d=identicon&r=PG
p214
sVuser_type
p215
Vregistered
p216
sVreputation
p217
I4362
sVlink
p218
Vhttp://stackoverflow.com/users/3665/gz
p219
sVdisplay_name
p220
Vgz.
p221
ssVis_accepted
p222
I01
sVanswer_id
p223
I43881370
sa(dp224
Vbody
p225
V<p>In the current CPython implementation, strings are reference-counted; it is assumed that a string cannot hold references to other objects because a string is not a container.  This means that garbage collection does not need to inspect or trace over string objects (because they're entirely covered by the reference counting).  But it's actually worse than that: Old versions of Python <em>did not have a tracing garbage collector at all</em>; GC was <a href="https://docs.python.org/2/whatsnew/2.0.html#garbage-collection-of-cycles" rel="nofollow noreferrer">new in 2.0</a>.  Before that, any cyclic garbage would simply leak.</p>\u000a\u000a<p>A competently-implemented substring-to-offset algorithm should not form cycles.  So in theory, a cyclic garbage collector is not a prerequisite for this.  However, because we're doing reference counting instead of tracing, the child objects become responsible for <code>Py_DECREF()</code>ing their parent objects at end-of-life.  Otherwise the parent leaks.  This means you cannot just chuck the whole string into the free list when it reaches end-of-life; you have to check whether it's a substring, and <a href="http://stackoverflow.com/questions/11227809/why-is-it-faster-to-process-a-sorted-array-than-an-unsorted-array">branching is potentially expensive</a>.  Python was historically designed to do string processing (like Perl, but with nicer syntax), which means creating and destroying a lot of strings.  Furthermore, all variable names are internally stored as strings, so even if the user is not doing string processing, the interpreter is.  Slowing down the string deallocation process by even a little could have a serious impact on performance.</p>\u000a
p226
sVquestion_id
p227
I43841023
sVlast_activity_date
p228
I1494305481
sVcreation_date
p229
I1494226950
sVscore
p230
I3
sVowner
p231
(dp232
Vuser_id
p233
I1340389
sVprofile_image
p234
Vhttps://www.gravatar.com/avatar/5d0e5b16679b92b24c8262e1e6aa2aa7?s=128&d=identicon&r=PG
p235
sVuser_type
p236
Vregistered
p237
sVreputation
p238
I13363
sVlink
p239
Vhttp://stackoverflow.com/users/1340389/kevin
p240
sVaccept_rate
p241
I75
sVdisplay_name
p242
VKevin
p243
ssVis_accepted
p244
I01
sVlast_edit_date
p245
I1494305481
sVanswer_id
p246
I43841625
sa(dp247
Vbody
p248
V<p>With this kind of programming challenge, I start by trying to answer the questions:</p>\u000a\u000a<ul>\u000a<li>How should the expressions be represented?</li>\u000a<li>Can we reduce number of possible expressions?</li>\u000a<li>Can we do less work for each expression?</li>\u000a</ul>\u000a\u000a<h2>Representing expressions</h2>\u000a\u000a<p>Problems that look like small programming languages tend to make me think Lisp. The problem is asking us to generate the series:</p>\u000a\u000a<pre><code>123\u000a(* 12 3)\u000a(+ 12 3)\u000a...\u000a(- (- 1 2) 3)\u000a</code></pre>\u000a\u000a<p>A binary expression in basically a 3-tuple of <code>(operator, left, right)</code> where left and right can also be expressions. The order of the components doesn't actually matter. Python has tuples, and in the <code>operator</code> module it has functions for the various binary ops. So, I'd plan to build expressions in the following form:</p>\u000a\u000a<pre><code>(operator.sub, (operator.sub, 1, 2), 3)\u000a</code></pre>\u000a\u000a<p>Which can then be evaluated with a (mostly) simple recursive function:</p>\u000a\u000a<pre><code>def compute(expr):\u000a    if isinstance(expr, tuple):\u000a            op, left, right = expr\u000a            return op(compute(left), compute(right))\u000a    return expr\u000a</code></pre>\u000a\u000a<h2>Reducing possibilities</h2>\u000a\u000a<p>From the problem description, it seems there will be an exponential number of possible expressions per digit given. Can we eliminate some of these part way through creating all the permutations?</p>\u000a\u000a<p>For example, take a six digit input and the target result <code>5</code>. During the process of creating the permutations, imagine the following expression has been created from the first four digits, and there are two left to be handled:</p>\u000a\u000a<pre><code>(* 42 81) '??'\u000a</code></pre>\u000a\u000a<p><code>3696</code> is a big number, are any of the expressions from this point even capable of getting a result of just <code>5</code>? Can we skip creating them altogether?</p>\u000a\u000a<p>Unfortunately, digits near the end can still make major changes:</p>\u000a\u000a<pre><code>(+ (* (* 42 81) 0) 5)\u000a</code></pre>\u000a\u000a<p>There may be some branches we could avoid, but we're going to have to consider most expressions.</p>\u000a\u000a<h2>Doing less work</h2>\u000a\u000a<p>Okay, given we'll have to actually get the result of a very large number of expressions, is there some other way to save effort?</p>\u000a\u000a<p>Lets imagine we're part way through generating a sequence, with these three final expressions generated one after the other:</p>\u000a\u000a<pre><code>...\u000a(* (- 8 (* 3 6)) 1)\u000a(+ (- 8 (* 3 6)) 1)\u000a(- (- 8 (* 3 6)) 1)\u000a...\u000a</code></pre>\u000a\u000a<p>They all give different results, <code>[12, 13, 11]</code>, but that inner part <code>(- 8 (* 3 6))</code> is the same, and will always be <code>12</code>. Our solution should look to take advantage of this.</p>\u000a\u000a<h2>An answer</h2>\u000a\u000a<p>For anyone in need of spoilers, I've put up <a href="https://git.launchpad.net/~gz/+git/soq43837842" rel="nofollow noreferrer">branches</a> for an <a href="https://git.launchpad.net/~gz/+git/soq43837842/tree/binop_parts.py?h=initial" rel="nofollow noreferrer">initial implementation</a> that calculates every expression from the top, a <a href="https://git.launchpad.net/~gz/+git/soq43837842/commit/?h=memoised&amp;id=1c20d41b6efce3c61d6cf8e999129cc365a82a5c" rel="nofollow noreferrer">minor change that memoises the calculation</a>, and a final one that <a href="https://git.launchpad.net/~gz/+git/soq43837842/commit/?h=precalculate&amp;id=4aba2b9634fa3e70cc2c7dcdef0c38b899e4ef60" rel="nofollow noreferrer">precomputes results</a> as the expressions are being generated plus some <a href="https://git.launchpad.net/~gz/+git/soq43837842/commit/?h=precalculate&amp;id=84c61db1f77691ed15427090994f01a7d19d0998" rel="nofollow noreferrer">minor tweaks</a>.</p>\u000a\u000a<ul>\u000a<li><code>17.40s elapsed 6180k max mem</code> original from question</li>\u000a<li><code>20.60s elapsed 6284k max mem</code> without eval from question</li>\u000a<li><code>4.65s elapsed 5356k max mem</code> my initial</li>\u000a<li><code>2.71s elapsed 5316k max mem</code> my memoised</li>\u000a<li><code>1.50s elapsed 5356k max mem</code> my precomputed</li>\u000a</ul>\u000a\u000a<p>Some notes on my implementation. The <code>generate()</code> function creates the candidate expressions by considering each point in the string and creating the possible next states. For example, at the start, both move the marker along, and split off the first number:</p>\u000a\u000a<pre><code>'3|456237490' -&gt;\u000a    '34|56237490' -&gt; ...\u000a    3 '4|56237490' -&gt;\u000a</code></pre>\u000a\u000a<p>Each pending state is pushed to a list, and the current one to consider is popped off each time through the loop. Continuing from the state at the end, the next possibilities are moving the marker along again, and splitting a number to make one of the three expressions.</p>\u000a\u000a<pre><code>        3 '45|6237490' -&gt; ...\u000a        (* 3 4) '5|6237490' -&gt; ...\u000a        (+ 3 4) '5|6237490' -&gt; ...\u000a        (- 3 4) '5|6237490' -&gt; ...\u000a</code></pre>\u000a\u000a<p>I have glossed over one wrinkle with operator precedence so far. When handling multiplication, we may need to rewrite an existing expression. Consider:</p>\u000a\u000a<pre><code>(+ 1 2) '3|' -&gt;\u000a    (* (+ 1 2) 3) '' # ???\u000a    (+ (+ 1 2) 3) ''\u000a    (- (+ 1 2) 3) ''\u000a</code></pre>\u000a\u000a<p>For addition and subtraction this is fine, order won't matter. However, <code>2 * 3</code> has to happen before <code>1 + ...</code>. In short, we need to push the multiplication inside:</p>\u000a\u000a<pre><code>(+ 1 2) 3 -&gt; (+ 1 (* 2 3))\u000a</code></pre>\u000a\u000a<p>There are neat ways to handle this by storing a bit more information about your operations beyond just the function to execute them. For this problem that's not really required, nor are other possible transformations like combining multiple expressions or factoring out irrelevant parts.</p>\u000a\u000a<p>Final implementation note, just to be difficult I made both the direction of iteration and (initially) the layout of the expressions backwards.</p>\u000a
p249
sVquestion_id
p250
I43837842
sVlast_activity_date
p251
I1494284902
sVcreation_date
p252
I1494200924
sVscore
p253
I5
sVowner
p254
(dp255
Vuser_id
p256
I3665
sVprofile_image
p257
Vhttps://www.gravatar.com/avatar/8cf559941da0220c8423ddb50efe42ec?s=128&d=identicon&r=PG
p258
sVuser_type
p259
Vregistered
p260
sVreputation
p261
I4362
sVlink
p262
Vhttp://stackoverflow.com/users/3665/gz
p263
sVdisplay_name
p264
Vgz.
p265
ssVis_accepted
p266
I01
sVlast_edit_date
p267
I1494284902
sVanswer_id
p268
I43837911
sa(dp269
Vbody
p270
V<p>This code occurs in <code>multiprocessing.dummy</code>, a "fake" version of <code>multiprocessing</code> that implements the functionality with threads. If you look down a few lines, you'll see</p>\u000a\u000a<pre><code>def Manager():\u000a    return sys.modules[__name__]\u000a</code></pre>\u000a\u000a<p><code>multiprocessing.dummy</code> implements <code>Manager</code> as a function that just returns the <code>multiprocessing.dummy</code> module itself, so the <code>multiprocessing.dummy</code> module object has to provide the API of a multiprocessing Manager object. The lines</p>\u000a\u000a<pre><code>dict = dict\u000alist = list\u000a</code></pre>\u000a\u000a<p>are there so you can do</p>\u000a\u000a<pre><code>m = multiprocessing.dummy.Manager()\u000ad = m.dict()\u000a</code></pre>\u000a\u000a<p>as if you had a real <code>multiprocessing.Manager()</code>.</p>\u000a
p271
sVquestion_id
p272
I43853407
sVlast_activity_date
p273
I1494264449
sVcreation_date
p274
I1494263760
sVscore
p275
I43
sVowner
p276
(dp277
Vuser_id
p278
I2357112
sVprofile_image
p279
Vhttps://www.gravatar.com/avatar/3f80897d57525afe9eac4fb8c8318052?s=128&d=identicon&r=PG
p280
sVuser_type
p281
Vregistered
p282
sVreputation
p283
I94866
sVlink
p284
Vhttp://stackoverflow.com/users/2357112/user2357112
p285
sVaccept_rate
p286
I33
sVdisplay_name
p287
Vuser2357112
p288
ssVis_accepted
p289
I01
sVlast_edit_date
p290
I1494264449
sVanswer_id
p291
I43853581
sa(dp292
Vbody
p293
V<p>When you have "big" things to run through, like this, the key to get things going fast is to "reduce algorithmic complexity" - that is, avoid any operations that depend on the size of either data set if possible.</p>\u000a\u000a<p>In the example you gave, you perform, for each of your millions of lines a 50 x 2000 linear search - that is a lot! The problem being that if each of your <code>final[esps]</code> is a list, Python performs a linear search in these 50 values - with the operator <code>in</code>. </p>\u000a\u000a<p>Since you mention you are reading your values from a file, I have to assume that both a[0] and the elements in the lines of <code>final</code> are strings - but this would also work for numbers.  </p>\u000a\u000a<p>A first, very simple optimization, is to simply change your <code>final</code> dictionary rows from lists into <code>set</code>s - with a <code>set</code> the match from the <code>in</code> operator changes from being linear to be in constant time (from O(m) to O(1) ) - so, you basically cut your search time by a factor of 50 if before running the code in your example you do:</p>\u000a\u000a<pre><code>for key in final:\u000a   final[key] = set(final[key])\u000a</code></pre>\u000a\u000a<p>But you are still performing a linear search in each of the 2010 keys of <code>final</code>. The way to change that into a constant search is to create a reversed dictionary - in which each of the 50 values in a row of <code>final</code> point to the key <code>esp</code> instead. Then you just use a[0] as the key in this reversed dictionary - and you are replacing a linear search in 100000 items (2000 x 50) for a search in constant time in a dictionary;</p>\u000a\u000a<p>That is easy to accomplish - just change your code to:</p>\u000a\u000a<pre><code>rfinal = {}\u000afor esp, values in final.items():\u000a   for value in values:\u000a       rfinal[value] = esp\u000a\u000a\u000afor a in aud:\u000a    if a[0] in rfinal:\u000a       a[0] = rfinal[a[0]]\u000a    else:\u000a       # code for when there is no match for a[0]\u000a       ...\u000a</code></pre>\u000a
p294
sVquestion_id
p295
I43827281
sVlast_activity_date
p296
I1494217299
sVcreation_date
p297
I1494125744
sVscore
p298
I23
sVowner
p299
(dp300
Vuser_id
p301
I108205
sVprofile_image
p302
Vhttps://www.gravatar.com/avatar/ef459127edc89cc575d80a73cd8c567a?s=128&d=identicon&r=PG
p303
sVuser_type
p304
Vregistered
p305
sVreputation
p306
I42482
sVlink
p307
Vhttp://stackoverflow.com/users/108205/jsbueno
p308
sVaccept_rate
p309
I86
sVdisplay_name
p310
Vjsbueno
p311
ssVis_accepted
p312
I01
sVlast_edit_date
p313
I1494217299
sVanswer_id
p314
I43827372
sa(dp315
Vbody
p316
V<p>It seems you're mostly interested in the difference between your function 3 compared to the <em>pure</em> NumPy (function 1) and Python (function 2) approaches. The answer is quite simple (especially if you look at function 4):</p>\u000a\u000a<ul>\u000a<li>NumPy functions have a "huge" constant factor.</li>\u000a</ul>\u000a\u000a<p>You typically need several thousand elements to get in the regime where the runtime of <code>np.sum</code> actually depends on the number of elements in the array. Using IPython and matplotlib (the plot is at the end of the answer) you can easily check the runtime dependency:</p>\u000a\u000a<pre><code>import numpy as np\u000a\u000an = []\u000atiming_sum1 = []\u000atiming_sum2 = []\u000afor i in range(1, 25):\u000a    num = 2**i\u000a    arr = np.arange(num)\u000a    print(num)\u000a    time1 = %timeit -o arr.sum()    # calling the method\u000a    time2 = %timeit -o np.sum(arr)  # calling the function\u000a    n.append(num)\u000a    timing_sum1.append(time1)\u000a    timing_sum2.append(time2)\u000a</code></pre>\u000a\u000a<p>The results for <code>np.sum</code> (shortened) are quite interesting:</p>\u000a\u000a<pre><code>4\u000a22.6 탎  297 ns per loop (mean  std. dev. of 7 runs, 10000 loops each)\u000a16\u000a25.1 탎  1.08 탎 per loop (mean  std. dev. of 7 runs, 10000 loops each)\u000a64\u000a25.3 탎  1.58 탎 per loop (mean  std. dev. of 7 runs, 10000 loops each)\u000a256\u000a24.1 탎  1.48 탎 per loop (mean  std. dev. of 7 runs, 10000 loops each)\u000a1024\u000a24.6 탎  221 ns per loop (mean  std. dev. of 7 runs, 10000 loops each)\u000a4096\u000a27.6 탎  147 ns per loop (mean  std. dev. of 7 runs, 10000 loops each)\u000a16384\u000a40.6 탎  1.29 탎 per loop (mean  std. dev. of 7 runs, 10000 loops each)\u000a65536\u000a91.2 탎  1.03 탎 per loop (mean  std. dev. of 7 runs, 10000 loops each)\u000a262144\u000a394 탎  8.09 탎 per loop (mean  std. dev. of 7 runs, 1000 loops each)\u000a1048576\u000a1.24 ms  4.38 탎 per loop (mean  std. dev. of 7 runs, 1000 loops each)\u000a4194304\u000a4.71 ms  22.9 탎 per loop (mean  std. dev. of 7 runs, 100 loops each)\u000a16777216\u000a18.6 ms  280 탎 per loop (mean  std. dev. of 7 runs, 100 loops each)\u000a</code></pre>\u000a\u000a<p>It seems the constant factor is roughly <code>20탎</code> on my computer) and it takes an array with 16384 thousand elements to double that time. So the timing for function 3 and 4 are mostly timing multiplicatives of the constant factor.</p>\u000a\u000a<p>In function 3 you include the constant factor 2 times, once with <code>np.sum</code> and once with <code>np.arange</code>. In this case <code>arange</code> is quite cheap because each array is the same size, so NumPy &amp; Python &amp; your OS probably reuse the memory of the array of the last iteration. However even that takes time (roughly <code>2탎</code> for very small arrays on my computer).</p>\u000a\u000a<p>More generally: To identify bottlenecks you should always profile the functions! </p>\u000a\u000a<p>I show the results for the functions with <a href="https://github.com/rkern/line_profiler" rel="nofollow noreferrer">line-profiler</a>. Therefore I altered the functions a bit so they only do one operation per line:</p>\u000a\u000a<pre><code>import numpy as np\u000a\u000adef func1():\u000a    x = np.arange(1000)\u000a    x = x*2\u000a    return np.sum(x)\u000a\u000adef func2():\u000a    sum_ = 0\u000a    for i in range(1000):\u000a        tmp = i*2\u000a        sum_ += tmp\u000a    return sum_\u000a\u000adef func3():\u000a    sum_ = 0\u000a    for i in range(0, 1000, 4):  # I'm using python3, so "range" is like "xrange"!\u000a        x = np.arange(i, i + 4, 1)\u000a        x = x * 2\u000a        tmp = np.sum(x)\u000a        sum_ += tmp\u000a    return sum_\u000a\u000adef func4():\u000a    sum_ = 0\u000a    x = np.arange(1000)\u000a    for i in range(0, 1000, 4):\u000a        y = x[i:i + 4]\u000a        y = y * 2\u000a        tmp = np.sum(y)\u000a        sum_ += tmp\u000a    return sum_\u000a</code></pre>\u000a\u000a<p>Results:</p>\u000a\u000a<pre><code>%load_ext line_profiler\u000a\u000a%lprun -f func1 func1()\u000aLine #      Hits         Time  Per Hit   % Time  Line Contents\u000a==============================================================\u000a     4                                           def func1():\u000a     5         1           62     62.0     23.8      x = np.arange(1000)\u000a     6         1           65     65.0     24.9      x = x*2\u000a     7         1          134    134.0     51.3      return np.sum(x)\u000a\u000a%lprun -f func2 func2()\u000aLine #      Hits         Time  Per Hit   % Time  Line Contents\u000a==============================================================\u000a     9                                           def func2():\u000a    10         1            7      7.0      0.1      sum_ = 0\u000a    11      1001         2523      2.5     30.9      for i in range(1000):\u000a    12      1000         2819      2.8     34.5          tmp = i*2\u000a    13      1000         2819      2.8     34.5          sum_ += tmp\u000a    14         1            3      3.0      0.0      return sum_\u000a\u000a%lprun -f func3 func3()\u000aLine #      Hits         Time  Per Hit   % Time  Line Contents\u000a==============================================================\u000a    16                                           def func3():\u000a    17         1            7      7.0      0.0      sum_ = 0\u000a    18       251          909      3.6      2.9      for i in range(0, 1000, 4):\u000a    19       250         6527     26.1     21.2          x = np.arange(i, i + 4, 1)\u000a    20       250         5615     22.5     18.2          x = x * 2\u000a    21       250        16053     64.2     52.1          tmp = np.sum(x)\u000a    22       250         1720      6.9      5.6          sum_ += tmp\u000a    23         1            3      3.0      0.0      return sum_\u000a\u000a%lprun -f func4 func4()\u000aLine #      Hits         Time  Per Hit   % Time  Line Contents\u000a==============================================================\u000a    25                                           def func4():\u000a    26         1            7      7.0      0.0      sum_ = 0\u000a    27         1           49     49.0      0.2      x = np.arange(1000)\u000a    28       251          892      3.6      3.4      for i in range(0, 1000, 4):\u000a    29       250         2177      8.7      8.3          y = x[i:i + 4]\u000a    30       250         5431     21.7     20.7          y = y * 2\u000a    31       250        15990     64.0     60.9          tmp = np.sum(y)\u000a    32       250         1686      6.7      6.4          sum_ += tmp\u000a    33         1            3      3.0      0.0      return sum_\u000a</code></pre>\u000a\u000a<p>I won't go into the details of the results, but as you can see <code>np.sum</code> is definetly the bottleneck in <code>func3</code> and <code>func4</code>. I already guessed that <code>np.sum</code> is the bottleneck before I wrote the answer but these line-profilings <strong>actually verify</strong> that it is <strong>the</strong> bottleneck.</p>\u000a\u000a<p>Which leads to a very important fact when using NumPy:</p>\u000a\u000a<ul>\u000a<li>Know when to use it! Small arrays aren't worth it (mostly).</li>\u000a<li>Know the NumPy functions and just use them. They already use (if avaiable) compiler optimization flags to unroll loops.</li>\u000a</ul>\u000a\u000a<p>If you really believe some part is too slow then you can use:</p>\u000a\u000a<ul>\u000a<li>NumPy's C API and process the array with C (can be really easy with Cython but you can also do it manually) </li>\u000a<li>Numba (based on LLVM). </li>\u000a</ul>\u000a\u000a<p>But generally you probably can't beat NumPy for moderatly sized (several thousand entries and more) arrays.</p>\u000a\u000a<hr>\u000a\u000a<h3>Visualization of the timings:</h3>\u000a\u000a<pre><code>%matplotlib notebook\u000a\u000aimport matplotlib.pyplot as plt\u000a\u000a# Average time per sum-call\u000afig = plt.figure(1)\u000aax = plt.subplot(111)\u000aax.plot(n, [time.average for time in timing_sum1], label='arr.sum()', c='red')\u000aax.plot(n, [time.average for time in timing_sum2], label='np.sum(arr)', c='blue')\u000aax.set_xscale('log')\u000aax.set_yscale('log')\u000aax.set_xlabel('elements')\u000aax.set_ylabel('time it takes to sum them [seconds]')\u000aax.grid(which='both')\u000aax.legend()\u000a\u000a# Average time per element\u000afig = plt.figure(1)\u000aax = plt.subplot(111)\u000aax.plot(n, [time.average / num for num, time in zip(n, timing_sum1)], label='arr.sum()', c='red')\u000aax.plot(n, [time.average / num for num, time in zip(n, timing_sum2)], label='np.sum(arr)', c='blue')\u000aax.set_xscale('log')\u000aax.set_yscale('log')\u000aax.set_xlabel('elements')\u000aax.set_ylabel('time per element [seconds / element]')\u000aax.grid(which='both')\u000aax.legend()\u000a</code></pre>\u000a\u000a<p>The plots are log-log, I think it was the best way to visualize the data given that it extends several orders of magnitude (I just hope it's still understandable).</p>\u000a\u000a<p>The first plot shows how much time it takes to do the <code>sum</code>:</p>\u000a\u000a<p><a href="https://i.stack.imgur.com/ugaBq.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/ugaBq.png" alt="enter image description here"></a></p>\u000a\u000a<p>The second plot shows the average time it takes to do the <code>sum</code> divided by the number of elements in the array. This is just another way to interpret the data:</p>\u000a\u000a<p><a href="https://i.stack.imgur.com/0U7st.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/0U7st.png" alt="enter image description here"></a></p>\u000a
p317
sVquestion_id
p318
I43823473
sVlast_activity_date
p319
I1494109700
sVcreation_date
p320
I1494096872
sVscore
p321
I8
sVowner
p322
(dp323
Vuser_id
p324
I5393381
sVprofile_image
p325
Vhttps://www.gravatar.com/avatar/308ffa6266fda6d94bc56fbd9e9798f9?s=128&d=identicon&r=PG&f=1
p326
sVuser_type
p327
Vregistered
p328
sVreputation
p329
I28421
sVlink
p330
Vhttp://stackoverflow.com/users/5393381/mseifert
p331
sVaccept_rate
p332
I94
sVdisplay_name
p333
VMSeifert
p334
ssVis_accepted
p335
I01
sVlast_edit_date
p336
I1494109700
sVanswer_id
p337
I43824239
sa(dp338
Vbody
p339
V<p>Python pre-computes calculations when compiling as a so-called <a href="https://en.wikipedia.org/wiki/Peephole_optimization" rel="noreferrer"><em>peep-hole optimisation</em></a>:</p>\u000a\u000a<pre><code>&gt;&gt;&gt; import dis\u000a&gt;&gt;&gt; def version2():\u000a...   return ((200*200 - 2) &amp; ((1 &lt;&lt; 500000000) - 1)) + ((200*200 - 2) &gt;&gt; 500000000)\u000a...\u000a&gt;&gt;&gt; dis.dis(version2)\u000a  2           0 LOAD_CONST              13 (39998)\u000a              2 RETURN_VALUE\u000a</code></pre>\u000a\u000a<p><code>version2()</code> returns the already-calculated value, and does <strong>no actual work</strong>. Returning a constant is of course much, much faster than having to calculate the value each time.</p>\u000a\u000a<p>See the <a href="https://github.com/python/cpython/blob/v3.6.1/Python/peephole.c#L221-L318" rel="noreferrer"><code>fold_binops_on_constants</code> function</a> in the <code>peephole.c</code> Python source file for the details on how the compiler does this.</p>\u000a\u000a<p>As a result, compiling <code>version2</code> takes (a lot) more time than <code>version1</code>:</p>\u000a\u000a<pre><code>&gt;&gt;&gt; import timeit\u000a&gt;&gt;&gt; version1_text = '''\u005c\u000a... def version1(n, p):\u000a...   return ((n*n - 2) &amp; ((1 &lt;&lt; p) - 1)) + ((n*n - 2) &gt;&gt; p)\u000a... '''\u000a&gt;&gt;&gt; version2_text = '''\u005c\u000a... def version2():\u000a...   return ((200*200 - 2) &amp; ((1 &lt;&lt; 500000000) - 1)) + ((200*200 - 2) &gt;&gt; 500000000)\u000a... '''\u000a&gt;&gt;&gt; timeit.timeit("compile(t, '', 'exec')", 'from __main__ import version1_text as t', number=10)\u000a0.00028649598243646324\u000a&gt;&gt;&gt; timeit.timeit("compile(t, '', 'exec')", 'from __main__ import version2_text as t', number=10)\u000a2.2103765579813626\u000a</code></pre>\u000a\u000a<p>Good thing Python caches the bytecode results of compilation!</p>\u000a\u000a<p>The intermediary results of each sub-expression is also stored in the <code>co_consts</code> attribute of the code object, and some of those are rather large:</p>\u000a\u000a<pre><code>&gt;&gt;&gt; import sys\u000a&gt;&gt;&gt; consts = version2.__code__.co_consts\u000a&gt;&gt;&gt; for obj in consts:\u000a...     size = sys.getsizeof(obj)\u000a...     print(f'{type(obj)!s:&lt;18} {size:&lt;8} {"&lt;too large to print&gt;" if size &gt; 100 else obj}')\u000a...\u000a&lt;class 'NoneType'&gt; 16       None\u000a&lt;class 'int'&gt;      28       200\u000a&lt;class 'int'&gt;      28       2\u000a&lt;class 'int'&gt;      28       1\u000a&lt;class 'int'&gt;      28       500000000\u000a&lt;class 'int'&gt;      28       40000\u000a&lt;class 'int'&gt;      28       39998\u000a&lt;class 'int'&gt;      66666692 &lt;too large to print&gt;\u000a&lt;class 'int'&gt;      66666692 &lt;too large to print&gt;\u000a&lt;class 'int'&gt;      28       39998\u000a&lt;class 'int'&gt;      28       40000\u000a&lt;class 'int'&gt;      28       39998\u000a&lt;class 'int'&gt;      24       0\u000a&lt;class 'int'&gt;      28       39998\u000a</code></pre>\u000a\u000a<p>so this did make the bytecode cache a little larger:</p>\u000a\u000a<pre><code>&gt;&gt;&gt; import marshal\u000a&gt;&gt;&gt; len(marshal.dumps(version1.__code__))\u000a129\u000a&gt;&gt;&gt; len(marshal.dumps(version2.__code__))\u000a133333481\u000a</code></pre>\u000a\u000a<p>That's a minimum of 127MB for the <code>.pyc</code> file for the module that contains your non-argument version!</p>\u000a
p340
sVquestion_id
p341
I43823807
sVlast_activity_date
p342
I1494096492
sVcreation_date
p343
I1494094292
sVscore
p344
I23
sVowner
p345
(dp346
Vuser_id
p347
I100297
sVprofile_image
p348
Vhttps://www.gravatar.com/avatar/24780fb6df85a943c7aea0402c843737?s=128&d=identicon&r=PG
p349
sVuser_type
p350
Vmoderator
p351
sVreputation
p352
I554222
sVlink
p353
Vhttp://stackoverflow.com/users/100297/martijn-pieters
p354
sVdisplay_name
p355
VMartijn Pieters
p356
ssVis_accepted
p357
I01
sVlast_edit_date
p358
I1494096492
sVanswer_id
p359
I43823830
sa(dp360
Vbody
p361
V<pre><code>d1 = df.set_index(['id', 'date']).is_local.unstack()\u000ad1.index[d1['2016-01-01'] &amp; ~d1['2017-01-01']].tolist()\u000a\u000a[123]\u000a</code></pre>\u000a
p362
sVquestion_id
p363
I43800643
sVlast_activity_date
p364
I1493975076
sVcreation_date
p365
I1493975076
sVscore
p366
I6
sVowner
p367
(dp368
Vuser_id
p369
I2336654
sVprofile_image
p370
Vhttps://i.stack.imgur.com/4dhPk.jpg?s=128&g=1
p371
sVuser_type
p372
Vregistered
p373
sVreputation
p374
I64656
sVlink
p375
Vhttp://stackoverflow.com/users/2336654/pirsquared
p376
sVaccept_rate
p377
I97
sVdisplay_name
p378
VpiRSquared
p379
ssVis_accepted
p380
I01
sVanswer_id
p381
I43800778
sa(dp382
Vbody
p383
V<p>Making the example reproducible, we can create the following text file (<code>data/timestamp01.csv</code>):</p>\u000a\u000a<pre><code>TIMESTAMP;eventid\u000a2017-03-20 02:38:24;1\u000a2017-03-21 05:59:41;1\u000a2017-03-23 12:59:58;1\u000a2017-03-24 01:00:07;1\u000a2017-03-27 03:00:13;1\u000a</code></pre>\u000a\u000a<p>(same for <code>data/timestamp00.csv</code>). We can then read them in</p>\u000a\u000a<pre><code>import pandas as pd\u000aimport matplotlib.pyplot as plt\u000aimport matplotlib.ticker as ticker\u000a\u000adf1 = pd.read_csv('data/timestamp01.csv', parse_dates=True, index_col='TIMESTAMP', sep=";")\u000adf0 = pd.read_csv('data/timestamp00.csv', parse_dates=True, index_col='TIMESTAMP', sep=";")\u000a</code></pre>\u000a\u000a<p>Plotting them</p>\u000a\u000a<pre><code>f, (ax1, ax2) = plt.subplots(1, 2)\u000a\u000aax1.plot(df0.resample('D').size())\u000aax2.plot(df1.resample('D').size())\u000a\u000aplt.setp(ax1.xaxis.get_majorticklabels(), rotation=30, ha="right")\u000aplt.setp(ax2.xaxis.get_majorticklabels(), rotation=30, ha="right")\u000aplt.show()\u000a</code></pre>\u000a\u000a<p>results in </p>\u000a\u000a<p><a href="https://i.stack.imgur.com/Q8Cz0.png" rel="noreferrer"><img src="https://i.stack.imgur.com/Q8Cz0.png" alt="enter image description here"></a></p>\u000a\u000a<p>which is the desired plot. </p>\u000a
p384
sVquestion_id
p385
I43744910
sVlast_activity_date
p386
I1493936861
sVcreation_date
p387
I1493936861
sVscore
p388
I7
sVowner
p389
(dp390
Vuser_id
p391
I4124317
sVprofile_image
p392
Vhttps://i.stack.imgur.com/wsHAV.png?s=128&g=1
p393
sVuser_type
p394
Vregistered
p395
sVreputation
p396
I25182
sVlink
p397
Vhttp://stackoverflow.com/users/4124317/importanceofbeingernest
p398
sVaccept_rate
p399
I86
sVdisplay_name
p400
VImportanceOfBeingErnest
p401
ssVis_accepted
p402
I01
sVanswer_id
p403
I43793737
sa(dp404
Vbody
p405
V<p>As the error states, you need to specify the scoring parameter in GridSearchCV.</p>\u000a\u000a<p>Use </p>\u000a\u000a<p><code>GridSearchCV(pipeline, param_grid=params, scoring = 'accuracy')</code></p>\u000a\u000a<p><strong>Edit</strong> (Based on questions in comments):</p>\u000a\u000a<p>If you need the roc, auc curve and f1 for the entire X_train and y_train (and not for all the splits of GridSearchCV), its better to keep the Perf class out of the pipeline.</p>\u000a\u000a<pre><code>pipeline = Pipeline([('fillna', FillNa()),\u000a                     ('categorical_to_numerical', CategoricalToNumerical()),\u000a                     ('features_selection', SelectKBest(k=nb_features)),\u000a                     ('random_forest', clf)])\u000a\u000a#Fit the data in the pipeline\u000apipeline.fit(X_train, y_train)\u000a\u000aperformance_meas = Perf()\u000aperformance_meas.fit(pipeline, X_train, y_train)\u000a</code></pre>\u000a
p406
sVquestion_id
p407
I43787107
sVlast_activity_date
p408
I1493914619
sVcreation_date
p409
I1493912156
sVscore
p410
I5
sVowner
p411
(dp412
Vuser_id
p413
I3374996
sVprofile_image
p414
Vhttps://www.gravatar.com/avatar/51dd62362e115108bc592abc49314bed?s=128&d=identicon&r=PG&f=1
p415
sVuser_type
p416
Vregistered
p417
sVreputation
p418
I2430
sVlink
p419
Vhttp://stackoverflow.com/users/3374996/vivek-kumar
p420
sVdisplay_name
p421
VVivek Kumar
p422
ssVis_accepted
p423
I01
sVlast_edit_date
p424
I1493914619
sVanswer_id
p425
I43787277
sa(dp426
Vbody
p427
V<p><code>type.__setattr__</code> has a check to prevent setting attributes on types like <code>int</code>, and it does a bunch of invisible cleanup that isn't needed for normal objects.</p>\u000a\u000a<hr>\u000a\u000a<p>Let's take a look under the hood! Here's <a href="https://github.com/python/cpython/blob/3.6/Objects/typeobject.c#L3075" rel="noreferrer"><code>type.__setattr__</code></a>:</p>\u000a\u000a<pre><code>static int\u000atype_setattro(PyTypeObject *type, PyObject *name, PyObject *value)\u000a{\u000a    if (!(type-&gt;tp_flags &amp; Py_TPFLAGS_HEAPTYPE)) {\u000a        PyErr_Format(\u000a            PyExc_TypeError,\u000a            "can't set attributes of built-in/extension type '%s'",\u000a            type-&gt;tp_name);\u000a        return -1;\u000a    }\u000a    if (PyObject_GenericSetAttr((PyObject *)type, name, value) &lt; 0)\u000a        return -1;\u000a    return update_slot(type, name);\u000a}\u000a</code></pre>\u000a\u000a<p>and if we examine <a href="https://github.com/python/cpython/blob/3.6/Objects/typeobject.c#L4508" rel="noreferrer"><code>PyBaseObject_Type</code></a>, we see it uses <code>PyObject_GenericSetAttr</code> for its <code>__setattr__</code>, the same call that appears halfway through <code>type_setattro</code>.</p>\u000a\u000a<p>Thus, <code>type.__setattr__</code> is like <code>object.__setattr__</code>, but with some additional handling wrapped around it.</p>\u000a\u000a<p>First, the <code>if (!(type-&gt;tp_flags &amp; Py_TPFLAGS_HEAPTYPE))</code> check prohibits attribute assignment on types written in C, like <code>int</code> or <code>numpy.array</code>, because assigning attributes on those can seriously screw up the Python internals in ways someone unfamiliar with the C API might not expect.</p>\u000a\u000a<p>Second, after the <code>PyObject_GenericSetAttr</code> call updates the type's dict or calls an appropriate descriptor from the metaclass, <code>update_slot</code> fixes up any <em>slots</em> affected by the attribute assignment. These slots are C-level function pointers that implement functionality like instance allocation, <code>in</code> checks, <code>+</code>, deallocation, etc. Most of them have corresponding Python-level methods, like <code>__contains__</code> or <code>__add__</code>, and if one of those Python-level methods is reassigned, the corresponding slot (or slots) have to be updated, too. <code>update_slot</code> also updates slots on all descendants of the class, and it invalidates entries in an internal attribute cache used for type object attributes.</p>\u000a
p428
sVquestion_id
p429
I43739608
sVlast_activity_date
p430
I1493751168
sVcreation_date
p431
I1493750723
sVscore
p432
I5
sVowner
p433
(dp434
Vuser_id
p435
I2357112
sVprofile_image
p436
Vhttps://www.gravatar.com/avatar/3f80897d57525afe9eac4fb8c8318052?s=128&d=identicon&r=PG
p437
sVuser_type
p438
Vregistered
p439
sVreputation
p440
I94866
sVlink
p441
Vhttp://stackoverflow.com/users/2357112/user2357112
p442
sVaccept_rate
p443
I33
sVdisplay_name
p444
Vuser2357112
p445
ssVis_accepted
p446
I01
sVlast_edit_date
p447
I1493751168
sVanswer_id
p448
I43745077
sa(dp449
Vbody
p450
V<p>TL;DR:  <em>It is safe, technically, but it's a poor choice stylistically.</em>  </p>\u000a\u000a<p>In a list comprehension, before binding the free variable of the for-loop to any object, Python will use a <code>GET_ITER</code> opcode on the iterable to get an iterator.  This is done just <strong>once</strong> at the beginning of the loop.  </p>\u000a\u000a<p>Therefore in the body of the "loop" of the list comprehension (which actually creates a scope in Python 3), you may rebind the name which originally pointed to the iterable without any consequence.  The iteration deals with a reference to the <em>iterator</em> directly, and whether or not it has a name in scope is irrelevant.  The same should hold true in Python 2, though the scoping implementation details are different: the name of the collection will be lost after the comprehension, as the loop variable name will remain bound to the final element of iteration.</p>\u000a\u000a<p>There is no advantage to writing the code in this way, and it is less readable than just avoiding the name collision.  So, you should prefer to name the collection so that it more obvious that it is a collection:</p>\u000a\u000a<pre><code>[f(x) for x in xs]\u000a</code></pre>\u000a
p451
sVquestion_id
p452
I43725990
sVlast_activity_date
p453
I1493698325
sVcreation_date
p454
I1493671247
sVscore
p455
I8
sVowner
p456
(dp457
Vuser_id
p458
I674039
sVprofile_image
p459
Vhttps://i.stack.imgur.com/leoFi.gif?s=128&g=1
p460
sVuser_type
p461
Vregistered
p462
sVreputation
p463
I97501
sVlink
p464
Vhttp://stackoverflow.com/users/674039/wim
p465
sVaccept_rate
p466
I95
sVdisplay_name
p467
Vwim
p468
ssVis_accepted
p469
I01
sVlast_edit_date
p470
I1493698325
sVanswer_id
p471
I43726205
sa(dp472
Vbody
p473
V<p>Use <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.r_.html" rel="nofollow noreferrer"><code>np.r_</code></a>:</p>\u000a\u000a<pre><code>import numpy as np\u000adf.drop(df.columns[np.r_[:10, 22, 26, -10, -5:0]], axis=1)\u000a</code></pre>\u000a\u000a<hr>\u000a\u000a<p>np.r_ concatenates several slices. For example, <code>np.r_[1:3, 5, 7:9, -3:0]</code> returns <code>array([ 1,  2,  5,  7,  8, -3, -2, -1])</code>. You can use this to index into <code>df.columns</code>. For a DataFrame of 40 columns (named <code>A1:A40</code>), </p>\u000a\u000a<pre><code>df.columns[np.r_[:3, 5, 7:9, -2:0]]\u000aOut: Index(['A1', 'A2', 'A3', 'A6', 'A8', 'A9', 'A39', 'A40'], dtype='object')\u000a</code></pre>\u000a\u000a<p>And finally, since it takes index labels, you can pass this to <code>df.drop</code>. The resulting DataFrame will have the following columns:</p>\u000a\u000a<pre><code>df.drop(df.columns[np.r_[:3, 5, 7:9, -2:0]], axis=1).columns\u000aOut: \u000aIndex(['A4', 'A5', 'A7', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16',\u000a       'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26',\u000a       'A27', 'A28', 'A29', 'A30', 'A31', 'A32', 'A33', 'A34', 'A35', 'A36',\u000a       'A37', 'A38'],\u000a      dtype='object') \u000a</code></pre>\u000a
p474
sVquestion_id
p475
I43723550
sVlast_activity_date
p476
I1493664630
sVcreation_date
p477
I1493660432
sVscore
p478
I8
sVowner
p479
(dp480
Vuser_id
p481
I2285236
sVprofile_image
p482
Vhttps://www.gravatar.com/avatar/5ac8c2e0f71dbd8cf4543039bebf2ab3?s=128&d=identicon&r=PG&f=1
p483
sVuser_type
p484
Vregistered
p485
sVreputation
p486
I19710
sVlink
p487
Vhttp://stackoverflow.com/users/2285236/ayhan
p488
sVaccept_rate
p489
I90
sVdisplay_name
p490
Vayhan
p491
ssVis_accepted
p492
I01
sVlast_edit_date
p493
I1493664630
sVanswer_id
p494
I43723651
sasVquota_max
p495
I300
sVquota_remaining
p496
I299
s.